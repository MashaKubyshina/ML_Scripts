**NER-BERT PROCESS STEP BY STEP**

This is a write-up I did for myself to better understand step by step process

Pre-process

DATA LOAD / PREP

GPU
Install transformer
Load data into dataframe
Create class to get the sentences from the dataframe
Check sentences
Labels (tag values from the dataframe)
Create tag values
Give index to these tag values

BERT

Import BERT, Tensor, torch.utils, keras, sklearn
Set batch size, length
Tokenize (load Bert tokenizer)
Tokenize and preserve labels (sentence, text labels)
Tokenize text labels using dataframe
Tokenize text
Tokenize labels
Input ids > convert to tokens
Tags  > convert to tokens
Attention_masks for input ids

Split data in test, train
Split data in inputs, tags, masks
Convert all segments to torch tensors
Set DataLoader

MODEL FINE-TUNING

From transformers import Bert for token classification and load the pre-trained model
Set AdamW optimizer, set for full fine-tuning
Set linear scheduler to reduce learning
Instal seqeval,  F1-score
Model.train (loss values, validation loss values)
Model.evaluate (evaluation loss, evaluation accuracy)
Output > accuracy score, F1-score
Plot (visualize training loss)


**QA BERT PROCESS STEP BY STEP**

Question Answering with BERT
(using SQuAD dataset)

Use distilbert if working from home

Prep work
Set the machine to GPU
Instal transformers
Import squad data files (2 files)
Look at the data (using json)
Important parts of the data:
	Contexts
	Questions
	Answers
Prepare the data (loop through context, question, answer)
Extract context, questions and answers from the dataset; split into train and validation
Set function to find the end of the answer
 
Encoding
Use transformers, use distilBertTokenizer
Tokenize the dataset, split in train_encodings, val_encodings
Set function to add token positions (start_positions, end_positions)
 
Initialize Dataset
Import torch, initialize dataset
Build partial (smaller) dataset (otherwise the program crashes)
 
Fine-Tune & Run the model
Dataloader
Instal sequel, import BertForQuestionAnswering, AdamW, tqdm, trange, f1_score, etc
Initialize Bert model (​​model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased'))
Run the model (optimizer and scheduler are inside the model)
Get the stats, accuracy score
Save the model (to use later)
Inference, run the model to find answers from the text
Download the model to your machine
